# ğŸ¾ Quadruped-Sim

Welcome to **Quadruped-Sim**, a simulation environment for a quadruped robot!

---

![Legged Robot](./img/legged-robot.png)  

## âœ¨ Installation

It is recommended to use a virtual environment (virtualenv or conda) with Python 3.6 or higher.

1. Install virtualenv via pip:

   ```bash
   pip install virtualenv
   ```

2. Create a virtual environment:

   ```bash
   virtualenv quad_env --python=python3
   ```

   *(You can replace **`quad_env`** with another name of your choice.)*

3. Activate the virtual environment:

   ```bash
   source {PATH_TO_VENV}/bin/activate
   ```

4. Your command prompt should now look like:

   ```bash
   (venv_name) user@pc:path$
   ```

5. Install the dependencies:

   ```bash
   pip install pybullet gym numpy stable-baselines3 matplotlib
   ```

---

## ğŸ—‚ Code Structure

### ğŸ› ï¸ Environment & Simulation

- [**env**](./env) - Quadruped environment files:
  - [quadruped\_gym\_env.py](./env/quadruped_gym_env.py) - Gym simulation environment.
  - [quadruped.py](./env/quadruped.py) - Robot-specific functionalities (inverse kinematics, leg Jacobian, etc.).
  - [configs\_a1.py](./env/configs_a1.py) - Configuration variables.

### ğŸ–Šï¸ Robot Description

- [**a1\_description**](./a1_description) - Contains the robot mesh files and URDF.

### ğŸ”„ CPG & Gait Control

- [**hopf\_network.py**](./env/hopf_network.py) - CPG class skeleton for various gaits.
- [**run\_cpg.py**](run_cpg.py) - Maps joint commands to an instance of `quadruped_gym_env`.

### ğŸ† Reinforcement Learning

- [**run\_sb3.py**](./run_sb3.py) & [**load\_sb3.py**](./load_sb3.py) - Interfaces for training RL algorithms using [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3).

### ğŸ“ Utilities

- [**utils**](./utils) - File I/O and plotting helpers.

---

## ğŸ“š Code Resources

- ğŸ“š [PyBullet Quickstart Guide](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3)
- ğŸŒŸ Inspired by [Google's motion-imitation repository](https://github.com/google-research/motion_imitation) ([Paper](https://xbpeng.github.io/projects/Robotic_Imitation/2020_Robotic_Imitation.pdf))
- ğŸ¤– RL frameworks: [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3), [Ray RLlib](https://github.com/ray-project/ray), [SpinningUp](https://github.com/openai/spinningup)

---

## ğŸ§ Conceptual Resources

The CPG and RL framework are based on:

- **CPG-RL: Learning Central Pattern Generators for Quadruped Locomotion** - IEEE Robotics and Automation Letters, 2022
  - [IEEE](https://ieeexplore.ieee.org/abstract/document/9932888)
  - [arXiv](https://arxiv.org/abs/2211.00458)
- **Robust High-speed Running for Quadruped Robots via Deep RL** - IROS 2022
  - [arXiv](https://arxiv.org/abs/2103.06484)

---

## ğŸ’¡ Tips & Tricks

- âš¡ If your simulation is slow, remove `time.sleep()` calls and disable camera resets in [quadruped\_gym\_env.py](./env/quadruped_gym_env.py).
- ğŸ¨ Modify the camera viewer in `_render_step_helper()` in [quadruped\_gym\_env.py](./env/quadruped_gym_env.py) to track the quadruped.

---

Enjoy simulating your quadruped! ğŸ¦œğŸš€

